{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip in_data/data-compressed.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports, need to only run this once\n",
    "!pip3 install numpy \n",
    "!pip3 install pandas \n",
    "!pip3 install torch torchvision \n",
    "!pip3 install scikit-learn\n",
    "!pip3 install xgboost\n",
    "!pip3 install category_encoders\n",
    "!pip3 install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "D_PATH = 'lish-moa/'\n",
    "\n",
    "train_features = pd.read_csv(D_PATH + 'train_features.csv')\n",
    "train_drug  = pd.read_csv(D_PATH + 'train_drug.csv')\n",
    "test_features = pd.read_csv(D_PATH + 'test_features.csv')\n",
    "train_targets_scored = pd.read_csv(D_PATH + 'train_targets_scored.csv' )\n",
    "train_targets_nonscored = pd.read_csv(D_PATH + 'train_targets_nonscored.csv' )\n",
    "\n",
    "tr_mask = train_features['cp_type']=='ctl_vehicle'\n",
    "ts_mask = test_features['cp_type']=='ctl_vehicle'\n",
    "\n",
    "# replace str to binary\n",
    "train_features['cp_dose'] = train_features['cp_dose'].replace({'D1': 0, 'D2': 1})\n",
    "train_features['cp_type'] = train_features['cp_type'].replace({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "test_features['cp_dose'] = test_features['cp_dose'].replace({'D1': 0, 'D2': 1})\n",
    "test_features['cp_type'] = test_features['cp_type'].replace({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "\n",
    "# Exclude rows where cp_type is \"ctl_vehicle\"\n",
    "X = train_features[~tr_mask]\n",
    "y = train_targets_scored[~tr_mask]\n",
    "\n",
    "\n",
    "#removing sig_id column \n",
    "X = X.iloc[:, 1:].to_numpy()\n",
    "submission_X_test = test_features.iloc[:, 1:].to_numpy() #only for the final submission\n",
    "y = y.iloc[:, 1:].to_numpy()\n",
    "\n",
    "#we are going to fake making a train, dev and test set \n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test, X_dev, y_test, y_dev = train_test_split(X_test, y_test, test_size=0.3333, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Assuming X and y are your input features and labels respectively\n",
    "\n",
    "# class PCALayer(nn.Module):\n",
    "#     def __init__(self, input_dim, output_dim):\n",
    "#         super(PCALayer, self).__init__()\n",
    "#         self.pca = PCA(n_components=output_dim)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         return torch.tensor(self.pca.fit_transform(x))\n",
    "\n",
    "# Define your model architecture\n",
    "class MultiLabelClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, pca_output_dim, num_classes, dropout_prob):\n",
    "        super(MultiLabelClassifier, self).__init__()\n",
    "        # self.pca_layer = PCALayer(input_size, pca_output_dim)\n",
    "        self.linear = nn.Linear(input_size, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear3 = nn.Linear(hidden_dim, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # self.linear = nn.Linear(input_size, num_classes)\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.linear(x))\n",
    "        out = self.dropout(out)\n",
    "        out = F.relu(self.linear2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear3(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "        # out = self.linear(x)\n",
    "        # out = self.sigmoid(out)\n",
    "        # return out\n",
    "\n",
    "\n",
    "def train(model, train_loader, num_epochs, criterion, optimizer, l1_lambda=0.001, l2_lambda=0.001):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)  # No need to convert labels to float here\n",
    "            \n",
    "            # L1 regularization\n",
    "            # l1_reg = torch.tensor(0., requires_grad=False)\n",
    "            # for param in model.parameters():\n",
    "            #     l1_reg += torch.norm(param.detach(), p=1)\n",
    "            # loss += l1_lambda * l1_reg\n",
    "\n",
    "            #L2 regularization\n",
    "            # l2_regularization = torch.tensor(0., requires_grad=True)\n",
    "            # for param in model.parameters():\n",
    "            #     l2_regularization = l2_regularization + torch.norm(param, 2)\n",
    "            # loss += 0.5 * l2_lambda * l2_regularization ** 2\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "\n",
    " \n",
    "\n",
    "def evaluate(model, test_loader, criterion):\n",
    "    # Set the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Convert probabilities to binary predictions\n",
    "            predicted_labels = (outputs > 0.5).float()\n",
    "\n",
    "            # Store true and predicted labels for later computation\n",
    "            true_labels.extend(labels.cpu().numpy().flatten())\n",
    "            pred_labels.extend(predicted_labels.cpu().numpy().flatten())\n",
    "\n",
    "            # Compute accuracy\n",
    "            total_correct += (predicted_labels == labels).sum().item()\n",
    "            total_samples += labels.size(0)*labels.size(1)\n",
    "\n",
    "            \n",
    "\n",
    "    # Calculate average loss\n",
    "    average_loss = total_loss / len(test_loader.dataset)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = total_correct / total_samples\n",
    "\n",
    "    # Calculate precision, recall, and F1 score using scikit-learn\n",
    "    precision = precision_score(true_labels, pred_labels)\n",
    "    recall = recall_score(true_labels, pred_labels)\n",
    "    f1 = f1_score(true_labels, pred_labels)\n",
    "\n",
    "    # f = plt.figure(dpi=800)\n",
    "    pred_labels = np.array(pred_labels)\n",
    "    pred_labels = pred_labels.reshape(y_test.shape[0], y_test.shape[1])\n",
    "    print(pred_labels.shape)\n",
    "    # print(pred_labels.shape)\n",
    "    \n",
    "    # print(disp_y.shape)\n",
    "    row_sums = np.sum(pred_labels, axis=1)\n",
    "\n",
    "    # Plot the distribution\n",
    "    plt.hist(row_sums, bins=np.arange(9)-0.5, align='mid', edgecolor='black')\n",
    "    plt.xlabel('Number of MoA\\'s ')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of MoA\\'s')\n",
    "    plt.yscale('log')\n",
    "    plt.xticks(range(8))\n",
    "    plt.grid(axis='y')  # Add gridlines for clarity\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Average Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "    return [average_loss, accuracy, precision, recall, f1]\n",
    "\n",
    "\n",
    "#hyper param tuning for hidden dimension \n",
    "hidden_dim_values = [50, 100, 400, 600, 800, 1000]\n",
    "# hidden_dim_values_2 = [30, 50, 300, 400, 600, 800]\n",
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "#iterate over each value of hidden dimension\n",
    "for i in range(len(hidden_dim_values)):\n",
    "\n",
    "    #Define loss function and optimizer\n",
    "    model = MultiLabelClassifier(input_size=X.shape[1], hidden_dim = hidden_dim_values[i], pca_output_dim = 30, num_classes=206, dropout_prob=0)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "    # Convert labels to probabilities\n",
    "    y_train_prob = y.astype(np.float32)  # Convert to float for torch.tensor\n",
    "    y_test_prob = y_test.astype(np.float32)\n",
    "\n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train_prob, dtype=torch.float32)  # Use probabilities\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test_prob, dtype=torch.float32)  # Use probabilities\n",
    "\n",
    "    # Create DataLoader for training and testing sets\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    #Train the model\n",
    "    train(model=model, train_loader=train_loader, num_epochs=25, criterion=criterion, optimizer=optimizer)\n",
    "    result = evaluate(model=model, test_loader=test_loader, criterion=criterion)\n",
    "\n",
    "    #store metrics\n",
    "    losses.append(result[0])\n",
    "    accuracies.append(result[1])\n",
    "    precisions.append(result[2])\n",
    "    recalls.append(result[3])\n",
    "    f1_scores.append(result[4])\n",
    "\n",
    "# Plot metrics against hidden dimension values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(hidden_dim_values, losses, label='Loss')\n",
    "plt.plot(hidden_dim_values, precisions, label='Precision')\n",
    "plt.plot(hidden_dim_values, recalls, label='Recall')\n",
    "plt.plot(hidden_dim_values, accuracies, label='Accuracy')\n",
    "plt.plot(hidden_dim_values, f1_scores, label='F1 Score')\n",
    "plt.xlabel('Hidden Dimension')\n",
    "plt.ylabel('Metrics')\n",
    "plt.title('Performance with PCA/Hidden Dimension Fixed For Layers (no regularization)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#printing histogram for MoA distribution\n",
    "# model = MultiLabelClassifier(input_size=X.shape[1], hidden_dim = 1000, pca_output_dim = 30, num_classes=206, dropout_prob=0)\n",
    "# criterion = nn.BCELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# # Convert labels to probabilities\n",
    "# y_train_prob = y.astype(np.float32)  # Convert to float for torch.tensor\n",
    "# y_test_prob = y_test.astype(np.float32)\n",
    "\n",
    "# # Convert numpy arrays to PyTorch tensors\n",
    "# X_train_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "# y_train_tensor = torch.tensor(y_train_prob, dtype=torch.float32)  # Use probabilities\n",
    "# X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "# y_test_tensor = torch.tensor(y_test_prob, dtype=torch.float32)  # Use probabilities\n",
    "\n",
    "# # Create DataLoader for training and testing sets\n",
    "# train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# #Train the model\n",
    "# train(model=model, train_loader=train_loader, num_epochs=25, criterion=criterion, optimizer=optimizer)\n",
    "# result = evaluate(model=model, test_loader=test_loader, criterion=criterion)\n",
    "\n",
    "\n",
    "\n",
    "#hyperparameter tuning for dropout layer probability\n",
    "# dropout_prob_values = [0, 0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "# losses = []\n",
    "# accuracies = []\n",
    "# precisions = []\n",
    "# recalls = []\n",
    "# f1_scores = []\n",
    "\n",
    "# #iterate over each value of hidden dimension\n",
    "# for i in range(len(dropout_prob_values)):\n",
    "\n",
    "#     #Define loss function and optimizer\n",
    "#     model = MultiLabelClassifier(input_size=X.shape[1], hidden_dim = 1000, pca_output_dim = 30, num_classes=206, dropout_prob=dropout_prob_values[i])\n",
    "#     criterion = nn.BCELoss()\n",
    "#     optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "#     # Convert labels to probabilities\n",
    "#     y_train_prob = y.astype(np.float32)  # Convert to float for torch.tensor\n",
    "#     y_test_prob = y_test.astype(np.float32)\n",
    "\n",
    "#     # Convert numpy arrays to PyTorch tensors\n",
    "#     X_train_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "#     y_train_tensor = torch.tensor(y_train_prob, dtype=torch.float32)  # Use probabilities\n",
    "#     X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "#     y_test_tensor = torch.tensor(y_test_prob, dtype=torch.float32)  # Use probabilities\n",
    "\n",
    "#     # Create DataLoader for training and testing sets\n",
    "#     train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "#     test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "#     test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "#     #Train the model\n",
    "#     train(model=model, train_loader=train_loader, num_epochs=25, criterion=criterion, optimizer=optimizer)\n",
    "#     result = evaluate(model=model, test_loader=test_loader, criterion=criterion)\n",
    "\n",
    "#     #store metrics\n",
    "#     losses.append(result[0])\n",
    "#     accuracies.append(result[1])\n",
    "#     precisions.append(result[2])\n",
    "#     recalls.append(result[3])\n",
    "#     f1_scores.append(result[4])\n",
    "\n",
    "# # Plot metrics against hidden dimension values\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(dropout_prob_values, losses, label='Loss')\n",
    "# plt.plot(dropout_prob_values, precisions, label='Precision')\n",
    "# plt.plot(dropout_prob_values, recalls, label='Recall')\n",
    "# plt.plot(dropout_prob_values, accuracies, label='Accuracy')\n",
    "# plt.plot(dropout_prob_values, f1_scores, label='F1 Score')\n",
    "# plt.xlabel('DropOut Probability')\n",
    "# plt.ylabel('Metrics')\n",
    "# plt.title('Performance of Different Dropout Probablity (no regularization, hidden dimension 1000)')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
